{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de23dd6f",
   "metadata": {},
   "source": [
    "# Facemask Live Detection Documentation\n",
    "This notebook explains how I built a real-time face mask detection system using a webcam, OpenCV, and a trained CNN model. The script uses Haar cascades for face detection and PyTorch for mask classification.\n",
    "\n",
    "> Just as a note: This notebook isn't meant to actually deploy the live detection feed. To do that, navigate to the live_detect.py file and run that. This notebook only creates a walkthrough of how the `live_detect.py` file was created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b4e061",
   "metadata": {},
   "source": [
    "## 1. Introduction & Overview\n",
    "\n",
    "This notebook provides a comprehensive walkthrough of the real-time face mask detection system we built using a CNN model, OpenCV, and PyTorch. It focuses specifically on the `live_detect.py` script, which connects webcam input to our trained classifier.\n",
    "\n",
    "**What I learnt:**\n",
    "\n",
    "- Loading and running a trained CNN model\n",
    "- Real-time face detection using Haar cascades\n",
    "- Preprocessing webcam frames for classification\n",
    "- Displaying model predictions live on the video feed\n",
    "\n",
    "**Project Structure:**\n",
    "\n",
    "- `src/`: Source code for training, evaluation, and live detection\n",
    "- `models/`: CNN model definition and trained weights\n",
    "- `data/`: Dataset used for training and testing\n",
    "- `notebooks/`: Documentation and demo notebooks\n",
    "- `requirements.txt`: Dependencies\n",
    "- `README.md`: Project instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d422c3c5",
   "metadata": {},
   "source": [
    "## 2. Live Detection Script Overview\n",
    "\n",
    "The script performs the following key tasks:\n",
    "- Loads the pretrained CNN model\n",
    "- Starts a webcam video stream\n",
    "- Detects faces using OpenCV’s Haar cascade\n",
    "- Applies preprocessing to each face\n",
    "- Uses the CNN to classify mask presence\n",
    "- Overlays the prediction on the video feed in real time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dd2a1d",
   "metadata": {},
   "source": [
    "## 3. Setup & Model Loading\n",
    "\n",
    "We begin by importing the required libraries, setting the device (CPU or GPU), and loading the trained CNN model.\n",
    "\n",
    "The model is stored in `models/facemask_cnn.pth` and is defined in `models/cnn.py`.\n",
    "\n",
    "We'll also define the image transformation pipeline that resizes and converts images for model input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1f7f79",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d33195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import sys\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748bc7c2",
   "metadata": {},
   "source": [
    "### CNN Model Definition\n",
    "> An explanation for this was outlined in `ModelDocumentation.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df12b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 56 * 56)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d2a872",
   "metadata": {},
   "source": [
    "Loading a trained model:\n",
    "> This block, and blocks from here onwards, are meant for explanation purposes only. They may not run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee04ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load(\"models/facemask_cnn.pth\", map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f88ec1e",
   "metadata": {},
   "source": [
    "We define the same CNN architecture used during training. We then load the saved model weights (`facemask_cnn.pth`) and switch the model to evaluation mode using `.eval()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7143a7be",
   "metadata": {},
   "source": [
    "## 4. Face Detection Setup\n",
    "\n",
    "We use OpenCV’s pre-trained Haar Cascade classifier to detect faces in each frame from the webcam feed.\n",
    "\n",
    "The detected face regions are passed to the model for mask classification.\n",
    "We also define an image transformation pipeline that:\n",
    "- Converts the image to PIL format\n",
    "- Resizes it to 224x224 (expected by the CNN)\n",
    "- Converts it into a normalized PyTorch tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af4e7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load Haar cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Image preprocessing transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab07c29",
   "metadata": {},
   "source": [
    "## 5. Webcam Feed and Inference Loop\n",
    "\n",
    "We now start the webcam feed using OpenCV. For each video frame:\n",
    "\n",
    "1. Detect faces using Haar cascade\n",
    "2. Preprocess each detected face\n",
    "3. Pass it through the CNN model\n",
    "4. Display the prediction (mask / no mask) with confidence on the live frame\n",
    "\n",
    "Press **'q'** to exit the video stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)  # Use 0 if your webcam doesn't open\n",
    "class_names = ['with_mask', 'without_mask']\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray, scaleFactor=1.1, minNeighbors=3, minSize=(30, 30), maxSize=(300, 300)\n",
    "    )\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            gray, scaleFactor=1.05, minNeighbors=2, minSize=(20, 20)\n",
    "        )\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "        face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        face_tensor = transform(face_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(face_tensor)\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            confidence, predicted = torch.max(probs, 1)\n",
    "\n",
    "        predicted_class = class_names[int(predicted.item())]\n",
    "        confidence_val = float(confidence.item()) * 100\n",
    "        mask_prob = float(probs[0, 0].item()) * 100\n",
    "        no_mask_prob = float(probs[0, 1].item()) * 100\n",
    "\n",
    "        display_text = f\"{predicted_class}: {confidence_val:.1f}%\"\n",
    "        detailed_text = f\"Mask: {mask_prob:.1f}% | No Mask: {no_mask_prob:.1f}%\"\n",
    "        color = (0, 255, 0) if predicted_class == 'with_mask' else (0, 0, 255)\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(frame, display_text, (x, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        cv2.putText(frame, detailed_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    cv2.imshow(\"Facemask Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960d9996",
   "metadata": {},
   "source": [
    "### Notes on Inference Loop\n",
    "\n",
    "- `cap = cv2.VideoCapture(1)`  \n",
    "  Starts the webcam stream. Use `0` if your webcam doesn't appear on `1`.\n",
    "\n",
    "- `gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)`  \n",
    "  Converts the frame to grayscale — Haar cascades work best on grayscale images.\n",
    "\n",
    "- `detectMultiScale(...)`  \n",
    "  Detects all faces in the frame. The backup detector with lower thresholds runs if no faces are found on the first pass.\n",
    "\n",
    "- `face = frame[y:y+h, x:x+w]`  \n",
    "  Crops the face region from the frame based on bounding box coordinates.\n",
    "\n",
    "- `transform(...)`  \n",
    "  Applies resizing and tensor conversion to prepare the cropped face for the CNN.\n",
    "\n",
    "- `torch.no_grad()`  \n",
    "  Disables gradient tracking for faster inference — required during evaluation.\n",
    "\n",
    "- `probs = torch.softmax(output, dim=1)`  \n",
    "  Converts logits to class probabilities.\n",
    "\n",
    "- `cv2.rectangle(...)` and `cv2.putText(...)`  \n",
    "  Draw a colored box around the face and display prediction text directly on the frame.\n",
    "\n",
    "- `'q'` to quit  \n",
    "  Pressing `'q'` stops the loop, releases the camera, and closes OpenCV windows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca435cf8",
   "metadata": {},
   "source": [
    "## 6. Summary & Takeaways\n",
    "\n",
    "This notebook documented the real-time face mask detection system step-by-step, based on the `live_detect.py` script.\n",
    "\n",
    "### What I built:\n",
    "- A webcam-based application using OpenCV for live video feed\n",
    "- Face detection using Haar cascades\n",
    "- Face mask classification using a pretrained CNN model\n",
    "- Real-time prediction display with confidence percentages\n",
    "\n",
    "### Key learnings:\n",
    "- How to preprocess webcam frames for deep learning models\n",
    "- How to integrate PyTorch models with OpenCV pipelines\n",
    "- How to use Haar cascades for efficient face detection\n",
    "- How to visualize model predictions in real time\n",
    "\n",
    "> This notebook is for documentation only and not meant to run live camera code inside Jupyter.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
